{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(alist, show=True):\n",
    "    print('type:%s\\nshape: %s' %(alist[0].dtype, alist[0].shape))\n",
    "    if show:\n",
    "        for i in range(3):\n",
    "            print('样本%s\\n%s' % (i, alist[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalars = np.array([1, 2, 3], dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:int64\n",
      "shape: ()\n",
      "样本0\n",
      "1\n",
      "样本1\n",
      "2\n",
      "样本2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "display(scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.array([[0.1, 0.1, 0.1], [0.2, 0.2, 0.2], [0.3, 0.3, 0.3]], dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.1, 0.1], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = np.array([np.array((vectors[0],vectors[0])),\n",
    "                    np.array((vectors[1],vectors[1])),\n",
    "                    np.array((vectors[2],vectors[2]))],dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1]],\n",
       "\n",
       "       [[0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2]],\n",
       "\n",
       "       [[0.3, 0.3, 0.3],\n",
       "        [0.3, 0.3, 0.3]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:float32\n",
      "shape: (2, 3)\n",
      "样本0\n",
      "[[0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1]]\n",
      "样本1\n",
      "[[0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2]]\n",
      "样本2\n",
      "[[0.3 0.3 0.3]\n",
      " [0.3 0.3 0.3]]\n"
     ]
    }
   ],
   "source": [
    "display(matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.python_io.TFRecordWriter('%s.tfrecord' % 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    features = {}\n",
    "    features['scalar'] = tf.train.Feature(int64_list=tf.train.Int64List(value=[scalars[i]]))\n",
    "    \n",
    "    features['vector'] = tf.train.Feature(float_list=tf.train.FloatList(value=vectors[i]))\n",
    "    \n",
    "    features['matrix'] = tf.train.Feature(float_list=tf.train.FloatList(value=matrices[i].reshape(-1)))\n",
    "    features['matrix_shape'] = tf.train.Feature(int64_list=tf.train.Int64List(value=matrices[i].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scalar': int64_list {\n",
       "   value: 3\n",
       " }, 'vector': float_list {\n",
       "   value: 0.30000001192092896\n",
       "   value: 0.30000001192092896\n",
       "   value: 0.30000001192092896\n",
       " }, 'matrix': float_list {\n",
       "   value: 0.30000001192092896\n",
       "   value: 0.30000001192092896\n",
       "   value: 0.30000001192092896\n",
       "   value: 0.30000001192092896\n",
       "   value: 0.30000001192092896\n",
       "   value: 0.30000001192092896\n",
       " }, 'matrix_shape': int64_list {\n",
       "   value: 2\n",
       "   value: 3\n",
       " }}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_features = tf.train.Features(feature=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_example = tf.train.Example(features=tf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_serialized = tf_example.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.write(tf_serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"test.tfrecord\", \"test.tfrecord\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfrecorder import TFrecorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-5f45bee47b71>:1: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data.\n",
      "WARNING:tensorflow:From /Users/ethan/MyCodes/tensorflow-the-master-way/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/ethan/MyCodes/tensorflow-the-master-way/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/ethan/MyCodes/tensorflow-the-master-way/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/ethan/MyCodes/tensorflow-the-master-way/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/ethan/MyCodes/tensorflow-the-master-way/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/ethan/MyCodes/tensorflow-the-master-way/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11b5feeb8>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11bbf2518>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11bbf24e0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'name':['image', 'label'],\n",
    "                  'type':['float32', 'int64'],\n",
    "                  'shape':[(784,),()],\n",
    "                  'isbyte':[False, False],\n",
    "                  'length_type':['fixed', 'fixed'],\n",
    "                  'default':[np.NaN, np.NaN]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr = TFrecorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mnist.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet at 0x11b5feeb8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'mnist_tfrecord/train/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples_per_file = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_so_far = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.python_io.TFRecordWriter('%s%s_%s.tfrecord' % (path, num_so_far, num_examples_per_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved mnist_tfrecord/train/train1000_2000.tfrecord\n",
      "saved mnist_tfrecord/train/train2000_3000.tfrecord\n",
      "saved mnist_tfrecord/train/train3000_4000.tfrecord\n",
      "saved mnist_tfrecord/train/train4000_5000.tfrecord\n",
      "saved mnist_tfrecord/train/train5000_6000.tfrecord\n",
      "saved mnist_tfrecord/train/train6000_7000.tfrecord\n",
      "saved mnist_tfrecord/train/train7000_8000.tfrecord\n",
      "saved mnist_tfrecord/train/train8000_9000.tfrecord\n",
      "saved mnist_tfrecord/train/train9000_10000.tfrecord\n",
      "saved mnist_tfrecord/train/train10000_11000.tfrecord\n",
      "saved mnist_tfrecord/train/train11000_12000.tfrecord\n",
      "saved mnist_tfrecord/train/train12000_13000.tfrecord\n",
      "saved mnist_tfrecord/train/train13000_14000.tfrecord\n",
      "saved mnist_tfrecord/train/train14000_15000.tfrecord\n",
      "saved mnist_tfrecord/train/train15000_16000.tfrecord\n",
      "saved mnist_tfrecord/train/train16000_17000.tfrecord\n",
      "saved mnist_tfrecord/train/train17000_18000.tfrecord\n",
      "saved mnist_tfrecord/train/train18000_19000.tfrecord\n",
      "saved mnist_tfrecord/train/train19000_20000.tfrecord\n",
      "saved mnist_tfrecord/train/train20000_21000.tfrecord\n",
      "saved mnist_tfrecord/train/train21000_22000.tfrecord\n",
      "saved mnist_tfrecord/train/train22000_23000.tfrecord\n",
      "saved mnist_tfrecord/train/train23000_24000.tfrecord\n",
      "saved mnist_tfrecord/train/train24000_25000.tfrecord\n",
      "saved mnist_tfrecord/train/train25000_26000.tfrecord\n",
      "saved mnist_tfrecord/train/train26000_27000.tfrecord\n",
      "saved mnist_tfrecord/train/train27000_28000.tfrecord\n",
      "saved mnist_tfrecord/train/train28000_29000.tfrecord\n",
      "saved mnist_tfrecord/train/train29000_30000.tfrecord\n",
      "saved mnist_tfrecord/train/train30000_31000.tfrecord\n",
      "saved mnist_tfrecord/train/train31000_32000.tfrecord\n",
      "saved mnist_tfrecord/train/train32000_33000.tfrecord\n",
      "saved mnist_tfrecord/train/train33000_34000.tfrecord\n",
      "saved mnist_tfrecord/train/train34000_35000.tfrecord\n",
      "saved mnist_tfrecord/train/train35000_36000.tfrecord\n",
      "saved mnist_tfrecord/train/train36000_37000.tfrecord\n",
      "saved mnist_tfrecord/train/train37000_38000.tfrecord\n",
      "saved mnist_tfrecord/train/train38000_39000.tfrecord\n",
      "saved mnist_tfrecord/train/train39000_40000.tfrecord\n",
      "saved mnist_tfrecord/train/train40000_41000.tfrecord\n",
      "saved mnist_tfrecord/train/train41000_42000.tfrecord\n",
      "saved mnist_tfrecord/train/train42000_43000.tfrecord\n",
      "saved mnist_tfrecord/train/train43000_44000.tfrecord\n",
      "saved mnist_tfrecord/train/train44000_45000.tfrecord\n",
      "saved mnist_tfrecord/train/train45000_46000.tfrecord\n",
      "saved mnist_tfrecord/train/train46000_47000.tfrecord\n",
      "saved mnist_tfrecord/train/train47000_48000.tfrecord\n",
      "saved mnist_tfrecord/train/train48000_49000.tfrecord\n",
      "saved mnist_tfrecord/train/train49000_50000.tfrecord\n",
      "saved mnist_tfrecord/train/train50000_51000.tfrecord\n",
      "saved mnist_tfrecord/train/train51000_52000.tfrecord\n",
      "saved mnist_tfrecord/train/train52000_53000.tfrecord\n",
      "saved mnist_tfrecord/train/train53000_54000.tfrecord\n",
      "saved mnist_tfrecord/train/train54000_55000.tfrecord\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(dataset.num_examples):\n",
    "    features = {}\n",
    "    tfr.feature_writer(df.iloc[0], dataset.images[i], features)\n",
    "    tfr.feature_writer(df.iloc[1], dataset.labels[i], features)\n",
    "    \n",
    "    tf_features = tf.train.Features(feature=features)\n",
    "    tf_example = tf.train.Example(features=tf_features)\n",
    "    tf_serialized = tf_example.SerializeToString()\n",
    "    writer.write(tf_serialized)\n",
    "    \n",
    "    if i%num_examples_per_file == 0 and i!=0:\n",
    "        writer.close()\n",
    "        num_so_far = i\n",
    "        writer = tf.python_io.TFRecordWriter('%s%s_%s.tfrecord' %(path, num_so_far, i+num_examples_per_file))\n",
    "        print('saved %s%s_%s.tfrecord' % (path, num_so_far, i+num_examples_per_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_path = 'mnist_tfrecord/data_info.csv'\n",
    "df.to_csv(data_info_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved mnist_tfrecord/test/test1000_2000.tfrecord\n",
      "saved mnist_tfrecord/test/test2000_3000.tfrecord\n",
      "saved mnist_tfrecord/test/test3000_4000.tfrecord\n",
      "saved mnist_tfrecord/test/test4000_5000.tfrecord\n",
      "saved mnist_tfrecord/test/test5000_6000.tfrecord\n",
      "saved mnist_tfrecord/test/test6000_7000.tfrecord\n",
      "saved mnist_tfrecord/test/test7000_8000.tfrecord\n",
      "saved mnist_tfrecord/test/test8000_9000.tfrecord\n",
      "saved mnist_tfrecord/test/test9000_10000.tfrecord\n"
     ]
    }
   ],
   "source": [
    "# 用该方法写测试集的tfrecord文件\n",
    "dataset = mnist.test\n",
    "path = 'mnist_tfrecord/test/test'\n",
    "# 每个tfrecord文件写多少个样本\n",
    "num_examples_per_file = 1000\n",
    "# 当前写的样本数\n",
    "num_so_far = 0\n",
    "# 要写入的文件\n",
    "writer = tf.python_io.TFRecordWriter('%s%s_%s.tfrecord' %(path, num_so_far, num_examples_per_file))\n",
    "# 写多个样本\n",
    "for i in np.arange(dataset.num_examples):\n",
    "    # 要写到tfrecord文件中的字典\n",
    "    features = {}\n",
    "    # 写一个样本的图片信息存到字典features中\n",
    "    tfr.feature_writer(df.iloc[0], dataset.images[i], features)\n",
    "    # 写一个样本的标签信息存到字典features中\n",
    "    tfr.feature_writer(df.iloc[1], dataset.labels[i], features)\n",
    "    \n",
    "    tf_features = tf.train.Features(feature= features)\n",
    "    tf_example = tf.train.Example(features = tf_features)\n",
    "    tf_serialized = tf_example.SerializeToString()\n",
    "    writer.write(tf_serialized)\n",
    "    # 每写了num_examples_per_file个样本就令生成一个tfrecord文件\n",
    "    if i%num_examples_per_file ==0 and i!=0:\n",
    "        writer.close()\n",
    "        num_so_far = i\n",
    "        writer = tf.python_io.TFRecordWriter('%s%s_%s.tfrecord' %(path, num_so_far, i+num_examples_per_file))\n",
    "        print('saved %s%s_%s.tfrecord' %(path, num_so_far, i+num_examples_per_file))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_maker(path, data_info_path, shuffle=False, batch_size=1, epoch=1, padding=None):\n",
    "    def input_fn():\n",
    "        filenames = tfr.get_filenames(path, shuffle=shuffle)\n",
    "        dataset = tfr.get_dataset(paths=filenames, data_info=data_info_path, shuffle=shuffle,\n",
    "                                 batch_size=batch_size, epoch=epoch, padding=padding)\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_info = ({'image': [784,], 'label':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = input_fn_maker('mnist_tfrecord/test/', 'mnist_tfrecord/data_info.csv', padding=padding_info)\n",
    "train_input_fn = input_fn_maker('mnist_tfrecord/train/', 'mnist_tfrecord/data_info.csv', shuffle=True, batch_size=512, padding=padding_info)\n",
    "train_eval_fn = input_fn_maker('mnist_tfrecord/train/', 'mnist_tfrecord/data_info.csv', batch_size=512, padding=padding_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, mode):\n",
    "    features['image'] = tf.reshape(features['image'], [-1, 28,28,1])\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=features['image'],\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu,\n",
    "        name='conv1')\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                                pool_size=[2, 2], \n",
    "                                                strides=2,\n",
    "                                                name='pool1')\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        fliters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu,\n",
    "        name='conv2')\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2,\n",
    "                                                pool_size=[2, 2],\n",
    "                                                strides=2,\n",
    "                                                name='pool2')\n",
    "    pool2_flat = tf.reshape(pool2,\n",
    "                                [-1, 7*7*64],\n",
    "                               name='pool2_flat')\n",
    "    dense1 = tf.layers.dense(inputs=pool2_flat,\n",
    "                                    units=1024,\n",
    "                                    activation=tf.nn.relu,\n",
    "                                    name='dense1')\n",
    "    dropout = tf.layers.dropout(inputs=dense1,\n",
    "                                           rate=0.4,\n",
    "                                           training_mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    logits = tf.layers.dense(input=dropout, units=10, name='output')\n",
    "    \n",
    "    predictions = {\n",
    "        \"image\": feature['image'],\n",
    "        \"conv1_out\":conv1,\n",
    "        \"pool1_out\":pool1,\n",
    "        \"conv2_out\":conv2,\n",
    "        \"pool2_out\":pool2,\n",
    "        \"pool2_flat_out\":pool2_flat,\n",
    "        \"dense1_out\":dense1,\n",
    "        \"logits\":logits,\n",
    "        \"classes\":tf.argmax(input=logits, axis=1),\n",
    "        \"labels\": features['label'],\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=features['label'], logits=logits)\n",
    "    if mode = tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "        train_op = optimizer.minimize(loss=loss,\n",
    "                                        global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
